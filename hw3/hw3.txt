(1)

1. What is the size of each element in this array? 
A: 8 bytes, because of line 11 addq $8, %rsi

2. How many rows are there in this array? 
A: 55 rows. In a row-major order, all elements of a row are stored before moving
to the next row. Therefore, the outer loop represents the row counter, checks if
it has processed the row before moving on to the next. 

3. How many columns are there in this array? 
A: 30 columns. The inner loop would represent columns. It is incremented (by
addq 8, %rsi) to the next elemnt (next column) in the same row.



(2) 
A. ttttttttssbb

Block offset: 2 
Set index: 2
Tag: 12 - 2 - 2 = 8 


B. 
Address  Binary Address                 Hit/Miss        Value 
0x831    100000110001    83 00 01       Hit             0x27
0x00B    000000001011    00 10 11       Hit             0x58
0x006    000000000110    00 01 10       Hit             0x56
0xFFE    111111111110    FF 11 10       Hit             0x08
0x54E    010101001110    54 11 10       Miss            unknown
0x54C    010101001100    54 11 00       Miss            n/a
0x007    000000000111    00 01 11       Hit             n/a
0x44C    010001001100    44 11 00       Miss            unknown
0xFFD    111111111101    FF 11 01       Hit             0xF1



(3)
A. 100%. 25% cold miss and 75% conflict miss 

512 / 16 = 32 blocks, each block holds 4 int. In directly mapped cache, each set
contains one block, so there are 32 sets (5 set index bits). The first access 
is a cold miss because the data is loaded for the first time. The next 3 may lead
to conflict misses if several addresses map to the same set. For instance, x[0][i] 
and x[1][i] are 512 bytes (128 elements * 4 (int)) apart, but the set index bits 
(which are the lower bits) might be the same and then evict each other.     


B. 25%. There would only be cold misses. 
1024 / 16 = 64 blocks, 64 sets in directly mapped sets, and thus 6 bits for the 
set index. For the example x[0][i] and x[1][i]:
x[0][i] (0x000 = 0000 0000 0000)
x[1][0] (0x200 = 0010 0000 0000)
Acessing the 6 bits for set index, we get 000000 and 100000, respectively. 

Each new block accessed initially will still result in a cold miss, but there's
no conflict between x[0][i] and x[1][i], so there will be hit.


C. 25% 
512 bytes / 16 bytes per block = 32 blocks.
32 blocks / 2 blocks per set = 16 sets. 
Each initial block would still result in a cold miss, but the two-way associativity 
allows x[0][i] and x[1][i] to be in the same set without evicting each other. 


D. No. The cache is a two-way set associative. This allows two blocks with the 
same set index to not evict each other, avoiding conflict misses. The rest of the
misses are cold misses, which depends on the first access to the data. Increasing
the cache size would increase the total capacity (potentially decreasing capacity
miss), but there would still be cold misses, which is the main type of misses here 
as two-way set associative reduced conflict misses already. 


E. Yes. A larger block size would mean the cache can load more consecutive 
data per block around that first address. This would then decrease cold misses. 
For example, in our 16-byte block, a cold miss occur every fourth element. But
if we incrase the block size, it's more likely that the element is in the cache 
when we try to access it. 